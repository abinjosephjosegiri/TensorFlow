{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images,test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 9 \n",
      "\n",
      "\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_images[0])\n",
    "print(\"Label\" , train_labels[0] ,\"\\n\\n\")\n",
    "print(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images  = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(128,activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 9 \n",
      "\n",
      "\n",
      "[[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.         0.         0.05098039 0.28627451\n",
      "  0.         0.         0.00392157 0.01568627 0.         0.         0.         0.         0.00392157 0.00392157 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.01176471 0.         0.14117647 0.53333333 0.49803922\n",
      "  0.24313725 0.21176471 0.         0.         0.         0.00392157 0.01176471 0.01568627 0.         0.         0.01176471]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.02352941 0.         0.4        0.8        0.69019608\n",
      "  0.5254902  0.56470588 0.48235294 0.09019608 0.         0.         0.         0.         0.04705882 0.03921569 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.60784314 0.9254902  0.81176471\n",
      "  0.69803922 0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608 0.30196078 0.50980392 0.28235294 0.05882353]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.         0.27058824 0.81176471 0.8745098  0.85490196\n",
      "  0.84705882 0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902 0.55294118 0.34509804 0.6745098  0.25882353]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.00392157 0.00392157 0.         0.78431373 0.90980392 0.90980392 0.91372549\n",
      "  0.89803922 0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922 0.48235294 0.76862745 0.89803922 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.71764706 0.88235294 0.84705882 0.8745098\n",
      "  0.89411765 0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667 0.8745098  0.96078431 0.67843137 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.75686275 0.89411765 0.85490196 0.83529412\n",
      "  0.77647059 0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098  0.8627451  0.95294118 0.79215686 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.01176471 0.         0.04705882 0.85882353 0.8627451  0.83137255 0.85490196\n",
      "  0.75294118 0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255 0.88627451 0.77254902 0.81960784 0.20392157]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.02352941 0.         0.38823529 0.95686275 0.87058824 0.8627451  0.85490196\n",
      "  0.79607843 0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451  0.96078431 0.46666667 0.65490196 0.21960784]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.01568627 0.         0.         0.21568627 0.9254902  0.89411765 0.90196078 0.89411765\n",
      "  0.94117647 0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039 0.85098039 0.81960784 0.36078431 0.        ]\n",
      " [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098 0.00784314 0.         0.         0.         0.         0.         0.92941176 0.88627451 0.85098039 0.8745098  0.87058824\n",
      "  0.85882353 0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725 0.85490196 1.         0.30196078 0.        ]\n",
      " [0.         0.01176471 0.         0.         0.         0.         0.         0.         0.         0.24313725 0.56862745 0.8        0.89411765 0.81176471 0.83529412 0.86666667 0.85490196\n",
      "  0.81568627 0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725 0.87843137 0.95686275 0.62352941 0.        ]\n",
      " [0.         0.         0.         0.         0.07058824 0.17254902 0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824 0.85098039 0.88627451 0.78431373 0.80392157 0.82745098\n",
      "  0.90196078 0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902 0.91372549 0.93333333 0.84313725 0.        ]\n",
      " [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667 0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784 0.78431373 0.62352941 0.96078431 0.75686275 0.80784314\n",
      "  0.8745098  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098 0.8627451  0.90980392 0.96470588 0.        ]\n",
      " [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098 0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451  0.94117647 0.31372549 0.58823529 1.         0.89803922\n",
      "  0.86666667 0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784 0.87058824 0.89411765 0.88235294 0.        ]\n",
      " [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922 0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725 0.85098039 0.94509804 0.25490196 0.28627451 0.41568627\n",
      "  0.45882353 0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098  0.8745098  0.87843137 0.89803922 0.11372549]\n",
      " [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157 0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314 0.77647059 0.83529412 0.94117647 0.76470588 0.89019608\n",
      "  0.96078431 0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824 0.8627451  0.86666667 0.90196078 0.2627451 ]\n",
      " [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902 0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569 0.85882353 0.86666667 0.8627451  0.9254902  0.88235294\n",
      "  0.84705882 0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098  0.70980392 0.80392157 0.80784314 0.45098039]\n",
      " [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824 0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471 0.82745098 0.82352941 0.78431373 0.76862745 0.76078431\n",
      "  0.74901961 0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471 0.65490196 0.69411765 0.82352941 0.36078431]\n",
      " [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961 0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549  0.74117647 0.7372549  0.75686275 0.77647059 0.8\n",
      "  0.81960784 0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431 0.75294118 0.84705882 0.66666667 0.        ]\n",
      " [0.00784314 0.         0.         0.         0.25882353 0.78431373 0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118 0.95686275 0.86666667 0.8627451  0.75686275 0.74901961\n",
      "  0.70196078 0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353 0.38823529 0.22745098 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431 0.1372549  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_images[0])\n",
    "print(\"Label\" , train_labels[0] ,\"\\n\\n\")\n",
    "print(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/500\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2817 - accuracy: 0.8952\n",
      "Epoch 2/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2685 - accuracy: 0.9000\n",
      "Epoch 3/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2571 - accuracy: 0.9040\n",
      "Epoch 4/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2480 - accuracy: 0.9058\n",
      "Epoch 5/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2391 - accuracy: 0.9101\n",
      "Epoch 6/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2310 - accuracy: 0.9137\n",
      "Epoch 7/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2238 - accuracy: 0.9155\n",
      "Epoch 8/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2152 - accuracy: 0.9202\n",
      "Epoch 9/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2101 - accuracy: 0.9219\n",
      "Epoch 10/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2027 - accuracy: 0.9245\n",
      "Epoch 11/500\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.1975 - accuracy: 0.9255\n",
      "Epoch 12/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1921 - accuracy: 0.9283\n",
      "Epoch 13/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1883 - accuracy: 0.9291\n",
      "Epoch 14/500\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1820 - accuracy: 0.9315\n",
      "Epoch 15/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1780 - accuracy: 0.9329\n",
      "Epoch 16/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1717 - accuracy: 0.9348\n",
      "Epoch 17/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1691 - accuracy: 0.9370\n",
      "Epoch 18/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.1668 - accuracy: 0.9371\n",
      "Epoch 19/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1609 - accuracy: 0.9392\n",
      "Epoch 20/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1568 - accuracy: 0.9422\n",
      "Epoch 21/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1544 - accuracy: 0.9423\n",
      "Epoch 22/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1509 - accuracy: 0.9441\n",
      "Epoch 23/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1488 - accuracy: 0.9435\n",
      "Epoch 24/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1448 - accuracy: 0.9452\n",
      "Epoch 25/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1404 - accuracy: 0.9472\n",
      "Epoch 26/500\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1368 - accuracy: 0.9480\n",
      "Epoch 27/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1334 - accuracy: 0.9506\n",
      "Epoch 28/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1300 - accuracy: 0.9506\n",
      "Epoch 29/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1276 - accuracy: 0.9521\n",
      "Epoch 30/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1285 - accuracy: 0.9511\n",
      "Epoch 31/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1247 - accuracy: 0.9529\n",
      "Epoch 32/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1225 - accuracy: 0.9535\n",
      "Epoch 33/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.1181 - accuracy: 0.9559\n",
      "Epoch 34/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1175 - accuracy: 0.9554\n",
      "Epoch 35/500\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1160 - accuracy: 0.9566\n",
      "Epoch 36/500\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.1113 - accuracy: 0.9578\n",
      "Epoch 37/500\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1103 - accuracy: 0.9592\n",
      "Epoch 38/500\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.1092 - accuracy: 0.9585\n",
      "Epoch 39/500\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.1063 - accuracy: 0.9609\n",
      "Epoch 40/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.1046 - accuracy: 0.9604\n",
      "Epoch 41/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.1041 - accuracy: 0.9607\n",
      "Epoch 42/500\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.1052 - accuracy: 0.9602\n",
      "Epoch 43/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.1008 - accuracy: 0.9624\n",
      "Epoch 44/500\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0994 - accuracy: 0.9631\n",
      "Epoch 45/500\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0970 - accuracy: 0.9644\n",
      "Epoch 46/500\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0930 - accuracy: 0.9657\n",
      "Epoch 47/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0942 - accuracy: 0.9642\n",
      "Epoch 48/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0931 - accuracy: 0.9653\n",
      "Epoch 49/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0911 - accuracy: 0.9662\n",
      "Epoch 50/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0898 - accuracy: 0.9668\n",
      "Epoch 51/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0874 - accuracy: 0.9678\n",
      "Epoch 52/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0895 - accuracy: 0.9668\n",
      "Epoch 53/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0874 - accuracy: 0.9680\n",
      "Epoch 54/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0833 - accuracy: 0.9687\n",
      "Epoch 55/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0837 - accuracy: 0.9686\n",
      "Epoch 56/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0830 - accuracy: 0.9697\n",
      "Epoch 57/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0800 - accuracy: 0.9707\n",
      "Epoch 58/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0795 - accuracy: 0.9707\n",
      "Epoch 59/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0782 - accuracy: 0.9706\n",
      "Epoch 60/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0780 - accuracy: 0.9711\n",
      "Epoch 61/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0751 - accuracy: 0.9719\n",
      "Epoch 62/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0765 - accuracy: 0.9714\n",
      "Epoch 63/500\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0730 - accuracy: 0.9725\n",
      "Epoch 64/500\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0744 - accuracy: 0.9729\n",
      "Epoch 65/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0718 - accuracy: 0.9735\n",
      "Epoch 66/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0721 - accuracy: 0.9733\n",
      "Epoch 67/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0706 - accuracy: 0.9740\n",
      "Epoch 68/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0681 - accuracy: 0.9745\n",
      "Epoch 69/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0689 - accuracy: 0.9743\n",
      "Epoch 70/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0668 - accuracy: 0.9753\n",
      "Epoch 71/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0673 - accuracy: 0.9753\n",
      "Epoch 72/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0653 - accuracy: 0.9755\n",
      "Epoch 73/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0669 - accuracy: 0.9754\n",
      "Epoch 74/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0621 - accuracy: 0.9771\n",
      "Epoch 75/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0648 - accuracy: 0.9760\n",
      "Epoch 76/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0637 - accuracy: 0.9764\n",
      "Epoch 77/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0633 - accuracy: 0.9766\n",
      "Epoch 78/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0608 - accuracy: 0.9783\n",
      "Epoch 79/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0642 - accuracy: 0.9762\n",
      "Epoch 80/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0578 - accuracy: 0.9784\n",
      "Epoch 81/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0621 - accuracy: 0.9769\n",
      "Epoch 82/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0573 - accuracy: 0.9789\n",
      "Epoch 83/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0582 - accuracy: 0.9782\n",
      "Epoch 84/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0580 - accuracy: 0.9784\n",
      "Epoch 85/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0562 - accuracy: 0.9791\n",
      "Epoch 86/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0593 - accuracy: 0.9781\n",
      "Epoch 87/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0572 - accuracy: 0.9793\n",
      "Epoch 88/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0580 - accuracy: 0.9781\n",
      "Epoch 89/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0547 - accuracy: 0.9797\n",
      "Epoch 90/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0555 - accuracy: 0.9796\n",
      "Epoch 91/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0528 - accuracy: 0.9803\n",
      "Epoch 92/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0556 - accuracy: 0.9791\n",
      "Epoch 93/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0524 - accuracy: 0.9808\n",
      "Epoch 94/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0537 - accuracy: 0.9800\n",
      "Epoch 95/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0535 - accuracy: 0.9807\n",
      "Epoch 96/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0513 - accuracy: 0.9812\n",
      "Epoch 97/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0511 - accuracy: 0.9806\n",
      "Epoch 98/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0499 - accuracy: 0.9815\n",
      "Epoch 99/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0480 - accuracy: 0.9827\n",
      "Epoch 100/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0507 - accuracy: 0.9818\n",
      "Epoch 101/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0492 - accuracy: 0.9815\n",
      "Epoch 102/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0473 - accuracy: 0.9827\n",
      "Epoch 103/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0447 - accuracy: 0.9839\n",
      "Epoch 104/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0494 - accuracy: 0.9824\n",
      "Epoch 105/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0466 - accuracy: 0.9821\n",
      "Epoch 106/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0481 - accuracy: 0.9819\n",
      "Epoch 107/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0446 - accuracy: 0.9838\n",
      "Epoch 108/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0454 - accuracy: 0.9833\n",
      "Epoch 109/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0414 - accuracy: 0.9856\n",
      "Epoch 110/500\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0498 - accuracy: 0.9814\n",
      "Epoch 111/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0452 - accuracy: 0.9838\n",
      "Epoch 112/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0428 - accuracy: 0.9836\n",
      "Epoch 113/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0449 - accuracy: 0.9828\n",
      "Epoch 114/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0427 - accuracy: 0.9843\n",
      "Epoch 115/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0439 - accuracy: 0.9839\n",
      "Epoch 116/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0416 - accuracy: 0.9844\n",
      "Epoch 117/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0418 - accuracy: 0.9852\n",
      "Epoch 118/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0413 - accuracy: 0.9848\n",
      "Epoch 119/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0420 - accuracy: 0.9846\n",
      "Epoch 120/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0396 - accuracy: 0.9853\n",
      "Epoch 121/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0430 - accuracy: 0.9840\n",
      "Epoch 122/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0409 - accuracy: 0.9850\n",
      "Epoch 123/500\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0384 - accuracy: 0.9861\n",
      "Epoch 124/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0405 - accuracy: 0.9855\n",
      "Epoch 125/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0372 - accuracy: 0.9863\n",
      "Epoch 126/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0383 - accuracy: 0.9858\n",
      "Epoch 127/500\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0397 - accuracy: 0.9852\n",
      "Epoch 128/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0363 - accuracy: 0.9866\n",
      "Epoch 129/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0379 - accuracy: 0.9864\n",
      "Epoch 130/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0358 - accuracy: 0.9866\n",
      "Epoch 131/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0407 - accuracy: 0.9854\n",
      "Epoch 132/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0342 - accuracy: 0.9879\n",
      "Epoch 133/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0387 - accuracy: 0.9855\n",
      "Epoch 134/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0371 - accuracy: 0.9862\n",
      "Epoch 135/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0375 - accuracy: 0.9865\n",
      "Epoch 136/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0361 - accuracy: 0.9871\n",
      "Epoch 137/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0347 - accuracy: 0.9872\n",
      "Epoch 138/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0342 - accuracy: 0.9873\n",
      "Epoch 139/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0367 - accuracy: 0.9870\n",
      "Epoch 140/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0329 - accuracy: 0.9879\n",
      "Epoch 141/500\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0351 - accuracy: 0.9874\n",
      "Epoch 142/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0340 - accuracy: 0.9876\n",
      "Epoch 143/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0338 - accuracy: 0.9877\n",
      "Epoch 144/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0360 - accuracy: 0.9873\n",
      "Epoch 145/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0366 - accuracy: 0.9866\n",
      "Epoch 146/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0312 - accuracy: 0.9883\n",
      "Epoch 147/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0337 - accuracy: 0.9877\n",
      "Epoch 148/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0322 - accuracy: 0.9888\n",
      "Epoch 149/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0326 - accuracy: 0.9879\n",
      "Epoch 150/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0340 - accuracy: 0.9879\n",
      "Epoch 151/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0328 - accuracy: 0.9879\n",
      "Epoch 152/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0326 - accuracy: 0.9878\n",
      "Epoch 153/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0324 - accuracy: 0.9879\n",
      "Epoch 154/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0328 - accuracy: 0.9887\n",
      "Epoch 155/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0310 - accuracy: 0.9891\n",
      "Epoch 156/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0307 - accuracy: 0.9888\n",
      "Epoch 157/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0303 - accuracy: 0.9895\n",
      "Epoch 158/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0341 - accuracy: 0.9879\n",
      "Epoch 159/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0271 - accuracy: 0.9905\n",
      "Epoch 160/500\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0319 - accuracy: 0.9885\n",
      "Epoch 161/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0283 - accuracy: 0.9899\n",
      "Epoch 162/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0320 - accuracy: 0.9888\n",
      "Epoch 163/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0334 - accuracy: 0.9887\n",
      "Epoch 164/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0277 - accuracy: 0.9899\n",
      "Epoch 165/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0331 - accuracy: 0.9882\n",
      "Epoch 166/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0263 - accuracy: 0.9901\n",
      "Epoch 167/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0299 - accuracy: 0.9893\n",
      "Epoch 168/500\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.98 - 6s 102us/sample - loss: 0.0303 - accuracy: 0.9896\n",
      "Epoch 169/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0314 - accuracy: 0.9887\n",
      "Epoch 170/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0249 - accuracy: 0.9910\n",
      "Epoch 171/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0317 - accuracy: 0.9887\n",
      "Epoch 172/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0276 - accuracy: 0.9903\n",
      "Epoch 173/500\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0290 - accuracy: 0.9895\n",
      "Epoch 174/500\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0276 - accuracy: 0.9906\n",
      "Epoch 175/500\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0273 - accuracy: 0.9902\n",
      "Epoch 176/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0283 - accuracy: 0.9898\n",
      "Epoch 177/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0259 - accuracy: 0.9903\n",
      "Epoch 178/500\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0268 - accuracy: 0.9900\n",
      "Epoch 179/500\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0288 - accuracy: 0.9902\n",
      "Epoch 180/500\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0250 - accuracy: 0.9912\n",
      "Epoch 181/500\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0280 - accuracy: 0.9901\n",
      "Epoch 182/500\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0249 - accuracy: 0.9912\n",
      "Epoch 183/500\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0256 - accuracy: 0.9912\n",
      "Epoch 184/500\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0264 - accuracy: 0.9911\n",
      "Epoch 185/500\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0261 - accuracy: 0.9908\n",
      "Epoch 186/500\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0256 - accuracy: 0.9913\n",
      "Epoch 187/500\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0256 - accuracy: 0.9907\n",
      "Epoch 188/500\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0265 - accuracy: 0.9903\n",
      "Epoch 189/500\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0272 - accuracy: 0.9906\n",
      "Epoch 190/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0274 - accuracy: 0.9902\n",
      "Epoch 191/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0255 - accuracy: 0.9913\n",
      "Epoch 192/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0266 - accuracy: 0.9905\n",
      "Epoch 193/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0221 - accuracy: 0.9923\n",
      "Epoch 194/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0299 - accuracy: 0.9900\n",
      "Epoch 195/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0260 - accuracy: 0.9908\n",
      "Epoch 196/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0230 - accuracy: 0.9919\n",
      "Epoch 197/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0272 - accuracy: 0.9904\n",
      "Epoch 198/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0237 - accuracy: 0.9919\n",
      "Epoch 199/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0242 - accuracy: 0.9915\n",
      "Epoch 200/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0243 - accuracy: 0.9913\n",
      "Epoch 201/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0231 - accuracy: 0.9922\n",
      "Epoch 202/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0276 - accuracy: 0.9906\n",
      "Epoch 203/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0222 - accuracy: 0.9923\n",
      "Epoch 204/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0235 - accuracy: 0.9919\n",
      "Epoch 205/500\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0265 - accuracy: 0.9905\n",
      "Epoch 206/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0213 - accuracy: 0.9922\n",
      "Epoch 207/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0223 - accuracy: 0.9926\n",
      "Epoch 208/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0286 - accuracy: 0.9902\n",
      "Epoch 209/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0225 - accuracy: 0.9923\n",
      "Epoch 210/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0234 - accuracy: 0.9924\n",
      "Epoch 211/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0242 - accuracy: 0.9914\n",
      "Epoch 212/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0219 - accuracy: 0.9924\n",
      "Epoch 213/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0227 - accuracy: 0.9918\n",
      "Epoch 214/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0246 - accuracy: 0.9912\n",
      "Epoch 215/500\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0208 - accuracy: 0.9927\n",
      "Epoch 216/500\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0237 - accuracy: 0.9917\n",
      "Epoch 217/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0240 - accuracy: 0.9920\n",
      "Epoch 218/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0208 - accuracy: 0.9927\n",
      "Epoch 219/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0227 - accuracy: 0.9923\n",
      "Epoch 220/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0241 - accuracy: 0.9918\n",
      "Epoch 221/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0236 - accuracy: 0.9918\n",
      "Epoch 222/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0181 - accuracy: 0.9934\n",
      "Epoch 223/500\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0262 - accuracy: 0.9915\n",
      "Epoch 224/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0190 - accuracy: 0.9927\n",
      "Epoch 225/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0232 - accuracy: 0.9925\n",
      "Epoch 226/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0249 - accuracy: 0.9916\n",
      "Epoch 227/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0246 - accuracy: 0.9916\n",
      "Epoch 228/500\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0227 - accuracy: 0.9924\n",
      "Epoch 229/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0233 - accuracy: 0.9927\n",
      "Epoch 230/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0214 - accuracy: 0.9923\n",
      "Epoch 231/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0180 - accuracy: 0.9936\n",
      "Epoch 232/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0239 - accuracy: 0.9918\n",
      "Epoch 233/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0224 - accuracy: 0.9922\n",
      "Epoch 234/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0234 - accuracy: 0.9921\n",
      "Epoch 235/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0227 - accuracy: 0.9919\n",
      "Epoch 236/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0211 - accuracy: 0.9930\n",
      "Epoch 237/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0244 - accuracy: 0.9914\n",
      "Epoch 238/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0213 - accuracy: 0.9927\n",
      "Epoch 239/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0195 - accuracy: 0.9931\n",
      "Epoch 240/500\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0209 - accuracy: 0.9929\n",
      "Epoch 241/500\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0217 - accuracy: 0.9927\n",
      "Epoch 242/500\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0186 - accuracy: 0.9936\n",
      "Epoch 243/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0198 - accuracy: 0.9934\n",
      "Epoch 244/500\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0197 - accuracy: 0.9930\n",
      "Epoch 245/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0237 - accuracy: 0.9919\n",
      "Epoch 246/500\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0216 - accuracy: 0.9930\n",
      "Epoch 247/500\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0190 - accuracy: 0.9938\n",
      "Epoch 248/500\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0189 - accuracy: 0.9940\n",
      "Epoch 249/500\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0230 - accuracy: 0.9925\n",
      "Epoch 250/500\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0178 - accuracy: 0.9936\n",
      "Epoch 251/500\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0229 - accuracy: 0.9920\n",
      "Epoch 252/500\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0196 - accuracy: 0.9934\n",
      "Epoch 253/500\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0216 - accuracy: 0.9927\n",
      "Epoch 254/500\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0145 - accuracy: 0.9953\n",
      "Epoch 255/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0212 - accuracy: 0.9929\n",
      "Epoch 256/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0217 - accuracy: 0.9926\n",
      "Epoch 257/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0205 - accuracy: 0.9929\n",
      "Epoch 258/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0202 - accuracy: 0.9930\n",
      "Epoch 259/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0199 - accuracy: 0.9930\n",
      "Epoch 260/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0188 - accuracy: 0.9935\n",
      "Epoch 261/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0217 - accuracy: 0.9931\n",
      "Epoch 262/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0178 - accuracy: 0.9941\n",
      "Epoch 263/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0196 - accuracy: 0.9934\n",
      "Epoch 264/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0204 - accuracy: 0.9930\n",
      "Epoch 265/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0192 - accuracy: 0.9934\n",
      "Epoch 266/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0208 - accuracy: 0.9927\n",
      "Epoch 267/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0165 - accuracy: 0.9944\n",
      "Epoch 268/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0225 - accuracy: 0.9923\n",
      "Epoch 269/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0182 - accuracy: 0.9941\n",
      "Epoch 270/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0189 - accuracy: 0.9933\n",
      "Epoch 271/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0159 - accuracy: 0.9944\n",
      "Epoch 272/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0231 - accuracy: 0.9926\n",
      "Epoch 273/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0169 - accuracy: 0.9946\n",
      "Epoch 274/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0168 - accuracy: 0.9948\n",
      "Epoch 275/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0158 - accuracy: 0.9948\n",
      "Epoch 276/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0245 - accuracy: 0.9919\n",
      "Epoch 277/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0174 - accuracy: 0.9944\n",
      "Epoch 278/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0200 - accuracy: 0.9936\n",
      "Epoch 279/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0165 - accuracy: 0.9941\n",
      "Epoch 280/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0212 - accuracy: 0.9929\n",
      "Epoch 281/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0168 - accuracy: 0.9947\n",
      "Epoch 282/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0186 - accuracy: 0.9940\n",
      "Epoch 283/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0203 - accuracy: 0.9934\n",
      "Epoch 284/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0164 - accuracy: 0.9944\n",
      "Epoch 285/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0154 - accuracy: 0.9948\n",
      "Epoch 286/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0230 - accuracy: 0.9922\n",
      "Epoch 287/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0181 - accuracy: 0.9941\n",
      "Epoch 288/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0169 - accuracy: 0.9944\n",
      "Epoch 289/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0189 - accuracy: 0.9937\n",
      "Epoch 290/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0172 - accuracy: 0.9944\n",
      "Epoch 291/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0173 - accuracy: 0.9940\n",
      "Epoch 292/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0162 - accuracy: 0.9945\n",
      "Epoch 293/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0201 - accuracy: 0.9933\n",
      "Epoch 294/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0143 - accuracy: 0.9954\n",
      "Epoch 295/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0175 - accuracy: 0.9940\n",
      "Epoch 296/500\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0186 - accuracy: 0.9942\n",
      "Epoch 297/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0191 - accuracy: 0.9938\n",
      "Epoch 298/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0189 - accuracy: 0.9941\n",
      "Epoch 299/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0149 - accuracy: 0.9950\n",
      "Epoch 300/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0172 - accuracy: 0.9940\n",
      "Epoch 301/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0188 - accuracy: 0.9937\n",
      "Epoch 302/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0182 - accuracy: 0.9941\n",
      "Epoch 303/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0140 - accuracy: 0.9950\n",
      "Epoch 304/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0203 - accuracy: 0.9933\n",
      "Epoch 305/500\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0160 - accuracy: 0.9946\n",
      "Epoch 306/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0138 - accuracy: 0.9956\n",
      "Epoch 307/500\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0217 - accuracy: 0.9931\n",
      "Epoch 308/500\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0191 - accuracy: 0.9937\n",
      "Epoch 309/500\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0124 - accuracy: 0.9958\n",
      "Epoch 310/500\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0198 - accuracy: 0.9935\n",
      "Epoch 311/500\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0164 - accuracy: 0.9945\n",
      "Epoch 312/500\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0174 - accuracy: 0.9945\n",
      "Epoch 313/500\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0189 - accuracy: 0.9936\n",
      "Epoch 314/500\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0147 - accuracy: 0.9952\n",
      "Epoch 315/500\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0177 - accuracy: 0.9941\n",
      "Epoch 316/500\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0187 - accuracy: 0.9939\n",
      "Epoch 317/500\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0131 - accuracy: 0.9957\n",
      "Epoch 318/500\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0164 - accuracy: 0.9946\n",
      "Epoch 319/500\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0210 - accuracy: 0.9939\n",
      "Epoch 320/500\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0158 - accuracy: 0.9949\n",
      "Epoch 321/500\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0145 - accuracy: 0.9954\n",
      "Epoch 322/500\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0205 - accuracy: 0.9934\n",
      "Epoch 323/500\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0158 - accuracy: 0.9949\n",
      "Epoch 324/500\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0163 - accuracy: 0.9946\n",
      "Epoch 325/500\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0182 - accuracy: 0.9943\n",
      "Epoch 326/500\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0162 - accuracy: 0.9948\n",
      "Epoch 327/500\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0139 - accuracy: 0.9952\n",
      "Epoch 328/500\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0147 - accuracy: 0.9955\n",
      "Epoch 329/500\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0193 - accuracy: 0.9938\n",
      "Epoch 330/500\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0162 - accuracy: 0.9946\n",
      "Epoch 331/500\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0193 - accuracy: 0.9940\n",
      "Epoch 332/500\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0161 - accuracy: 0.9950\n",
      "Epoch 333/500\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0151 - accuracy: 0.9955\n",
      "Epoch 334/500\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 335/500\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0175 - accuracy: 0.9943\n",
      "Epoch 336/500\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0181 - accuracy: 0.9941\n",
      "Epoch 337/500\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.0184 - accuracy: 0.9948\n",
      "Epoch 338/500\n",
      "   32/60000 [..............................] - ETA: 10s - loss: 1.5497e-06 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WzlqsEzX9s5P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 90us/sample - loss: 0.3624 - accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3624047348022461, 0.871]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
